# Fine-tuning VITS pour le dialecte arabe tunisien

Ce projet permet dâ€™effectuer un fine-tuning du modÃ¨le MMS-TTS sur un dataset de type Hugging Face (`Elyadata/TunArTTS`) pour gÃ©nÃ©rer une voix en arabe tunisien.

---

## ğŸ›  Ã‰tape 1 : Conversion du modÃ¨le original

Avant le fine-tuning, il est nÃ©cessaire de convertir les checkpoints du modÃ¨le original MMS :

```bash
python convert_original_discriminator_checkpoint.py \
  --language_code ara \
  --pytorch_dump_folder_path arabic-mms-checkpoint \
```

ğŸ‘‰ **Pourquoi ?**  
Le modÃ¨le original n'est pas directement exploitable. Cette conversion gÃ©nÃ¨re une version compatible avec Hugging Face et PyTorch, tout en permettant un Ã©ventuel push vers le hub.

---

## âš™ï¸ Ã‰tape 2 : PrÃ©parer la configuration du dataset

Dans le fichier de configuration JSON, plusieurs **attributs sont essentiels** pour que le dataset soit correctement utilisÃ© pendant l'entraÃ®nement :

| Attribut | Description |
|----------|-------------|
| `dataset_name` | Nom du dataset sur Hugging Face (ex. `"Elyadata/TunArTTS"`) |
| `dataset_config_name` | Configuration interne du dataset (souvent `"default"`) |
| `audio_column_name` | Nom de la colonne contenant les fichiers audio (ex. `"audio"`) |
| `text_column_name` | Nom de la colonne contenant les transcriptions (ex. `"tgt_text_without_diacritization"`) |
| `train_split_name` | Nom du split utilisÃ© pour l'entraÃ®nement (ex. `"train"`) |
| `eval_split_name` | Nom du split utilisÃ© pour lâ€™Ã©valuation (peut Ãªtre `"train"` si un seul split disponible) |

ğŸ“ **Remarque :**  
Ces noms doivent **correspondre exactement** Ã  ceux prÃ©sents dans le dataset sur Hugging Face. Vous pouvez les vÃ©rifier via [le dataset en ligne](https://huggingface.co/datasets/Elyadata/TunArTTS) ou via la fonction `load_dataset`.

---

## ğŸ”„ Ã‰tape 3 : TÃ©lÃ©charger le dataset localement (optionnel)

Si vous souhaitez tÃ©lÃ©charger le dataset localement plutÃ´t que d'y accÃ©der en ligne, vous pouvez le faire en utilisant la commande suivante :

```bash
from datasets import load_dataset
dataset = load_dataset("Elyadata/TunArTTS")
```

Si vous optez pour un chargement local du dataset, **le fichier de configuration doit Ãªtre modifiÃ©**. En effet, au lieu de spÃ©cifier simplement le nom du dataset sur Hugging Face dans le champ `dataset_name`, vous devez spÃ©cifier le chemin local oÃ¹ le dataset est stockÃ©, comme ceci :

```json
"dataset_name": "/chemin/vers/votre/dataset",
```

Cela permet Ã  votre script de charger le dataset localement sans tenter de le rÃ©cupÃ©rer en ligne. Assurez-vous Ã©galement que les colonnes (`audio_column_name`, `text_column_name`) sont correctement dÃ©finies pour le chemin local.

---

## ğŸ“ VÃ©rification du vocabulaire

Il est essentiel de vÃ©rifier que le vocabulaire du dataset correspond au vocabulaire avec lequel le modÃ¨le a Ã©tÃ© entraÃ®nÃ©. Pour cela, aprÃ¨s avoir exÃ©cutÃ© la commande de conversion du modÃ¨le, vous trouverez un fichier **`vocab.json`** dans le rÃ©pertoire oÃ¹ le modÃ¨le a Ã©tÃ© sauvegardÃ© (`arabic-mms-checkpoint`). Ce fichier contient le vocabulaire utilisÃ© pour l'entraÃ®nement du modÃ¨le.

Assurez-vous que votre dataset utilise un vocabulaire compatible avec celui contenu dans ce fichier afin de garantir une correspondance correcte lors du fine-tuning.

---

## ğŸš€ Ã‰tape 4 : Lancer le fine-tuning

Une fois le fichier de config prÃªt et le vocabulaire vÃ©rifiÃ©, vous pouvez lancer lâ€™entraÃ®nement avec :

```bash
accelerate launch run_vits_finetuning.py training_config_arabic.json
```

---

## ğŸ“Œ RÃ©sumÃ©

- Convertir le modÃ¨le MMS original avec `convert_original_discriminator_checkpoint.py`
- CrÃ©er un fichier de configuration JSON avec les bons attributs liÃ©s au dataset
- Si vous chargez le dataset localement, mettre Ã  jour `dataset_name` avec le chemin local
- VÃ©rifier que le vocabulaire du dataset correspond au vocabulaire du modÃ¨le (fichier `vocab.json`)
- Lancer le fine-tuning avec `accelerate`

---
